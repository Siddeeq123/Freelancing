{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "932579ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a67bd6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n"
     ]
    }
   ],
   "source": [
    "# now define path to dataset\n",
    "path=\"NewDataSet\"\n",
    "files=os.listdir(path)\n",
    "# list of files in path\n",
    "# sort path from A-Y\n",
    "files.sort()\n",
    "\n",
    "# print to see list\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d65298d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:22<00:00,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "image_array=[]\n",
    "label_array=[]\n",
    "# loop through each file in files\n",
    "\n",
    "for i in tqdm(range(len(files))):\n",
    "\t# list of image in each folder\n",
    "\tsub_file=os.listdir(path+\"/\"+files[i])\n",
    "\t# let's check length of each folder\n",
    "\t#\tprint(len(sub_file))\n",
    "\n",
    "\t# loop through each sub folder\n",
    "\tfor j in range(len(sub_file)):\n",
    "\n",
    "\t\t# path of each image\n",
    "\t\t#Example:imagepro/A/image_name1.jpg\n",
    "\n",
    "\t\tfile_path=path+\"/\"+files[i]+\"/\"+sub_file[j]\n",
    "\t\t# read each image\n",
    "\n",
    "\t\timage=cv2.imread(file_path)\n",
    "\n",
    "\t\t# resize image by 96x96\n",
    "\t\timage=cv2.resize(image,(224,224))\n",
    "\t\t# convert BGR image to RGB image\n",
    "\t\timage=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\t\t# add this image at image_array\n",
    "\t\timage_array.append(image)\n",
    "\n",
    "\t\t# add label to label_array\n",
    "\t\t# i is number from 0 to len(files)-1\n",
    "\t\t# so we can use it as label\n",
    "\t\tlabel_array.append(i)\n",
    "\n",
    "# save and run to see if it is working or not\n",
    "# before that apply tqdm to for loop\n",
    "# it is working with no errors\n",
    "\n",
    "# convert list to array\n",
    "\n",
    "image_array=np.array(image_array)\n",
    "label_array=np.array(label_array,dtype=\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3962d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# output\t\t\t\t\t\t\t\t\t   train image   label      spliting size\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(image_array,label_array,test_size=0.2)\n",
    "\n",
    "del image_array,label_array\n",
    "\n",
    "# to free memory \n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# X_train will have 85% of images \n",
    "# X_test will have 15% of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1efe17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb0 (Functional)  (None, 7, 7, 1280)       4049571   \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,050,852\n",
      "Trainable params: 4,008,829\n",
      "Non-trainable params: 42,023\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a model\n",
    "\n",
    "from keras import layers,callbacks,utils,applications,optimizers\n",
    "from keras.models import Sequential, Model, load_model\n",
    "\n",
    "model=Sequential()\n",
    "# add pretrained models to Sequential model\n",
    "# I will use EfficientNetB0 pretrained model. You can try different model.\n",
    "pretrained_model=tf.keras.applications.EfficientNetB0(input_shape=(224,224,3),include_top=False)\n",
    "\n",
    "model.add(pretrained_model)\n",
    "\n",
    "# add Pooling to model\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "# add dropout to model\n",
    "# We add dropout to increase accuracy by reduce overfitting\n",
    "model.add(layers.Dropout(0.3))\n",
    "# finally we will addd dense layer as an output\n",
    "model.add(layers.Dense(1))\n",
    "# For some tensorflow version we required to build model\n",
    "model.build(input_shape=(None,224,224,3))\n",
    "\n",
    "\n",
    "# to see model summary\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# save and run to see model summary \n",
    "# make sure your pc is connected to internet to download pretrained weight\n",
    "# It will take some time\n",
    "# Everything till now works\n",
    "# I am using GPU to train model so it will take 20-30 min.\n",
    "# If you train model on CPU it will take some time\n",
    "\n",
    "\n",
    "# compile model\n",
    "# you can use different optimizer and loss function to increase accuracy\n",
    "model.compile(optimizer=\"adam\",loss=\"mae\",metrics=[\"mae\"])\n",
    "\n",
    "# create a checkpoint to save best accuracy model\n",
    "ckp_path=\"trained_model/model\"\n",
    "model_checkpoint=tf.keras.callbacks.ModelCheckpoint(\n",
    "\t\t\t\t\t\t\t\t\tfilepath=ckp_path,\n",
    "\t\t\t\t\t\t\t\t\tmonitor=\"val_mae\",\n",
    "\t\t\t\t\t\t\t\t\tmode=\"auto\",\n",
    "\t\t\t\t\t\t\t\t\tsave_best_only=True,\n",
    "\t\t\t\t\t\t\t\t\tsave_weights_only=True\n",
    "\t\t\t\t\t\t\t\t\t)\n",
    "# monitor: monitor validation mae loss to save model\n",
    "# mode: Use to save model when val_mae is minimum or maximum\n",
    "# It has 3 option: \"min\",\"max\",\"auto\".\n",
    "# for us you can select either \"min\" or \"auto\"\n",
    "# When val_mae reduce model will be saved\n",
    "# save_best_only: False -> It will save all model\n",
    "# save_weights_only: Save only weight.\n",
    "\n",
    "\n",
    "# create learning rate reducer to reduce lr when accuracy does not improve\n",
    "# Correct \n",
    "reduce_lr=tf.keras.callbacks.ReduceLROnPlateau(\n",
    "\t\t\t\t\t\t\t\t\tfactor=0.9,\n",
    "\t\t\t\t\t\t\t\t\tmonitor=\"val_mae\",\n",
    "\t\t\t\t\t\t\t\t\tmode=\"auto\",\n",
    "\t\t\t\t\t\t\t\t\tcooldown=0,\n",
    "\t\t\t\t\t\t\t\t\tpatience=5,\n",
    "\t\t\t\t\t\t\t\t\tverbose=1,\n",
    "\t\t\t\t\t\t\t\t\tmin_lr=1e-6)\n",
    "\n",
    "# factor: when it is reduce next lr will be 0.9 times of current\n",
    "# next lr= 0.9* current lr\n",
    "\n",
    "# patience=X\n",
    "# reduce lr after X epoch when accuracy does not improve\n",
    "# verbose : show it after every epoch\n",
    "\n",
    "# min_lr : minimum learning rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "895c7b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "196/196 [==============================] - 55s 229ms/step - loss: 2.8018 - mae: 2.8018 - val_loss: 2.3221 - val_mae: 2.3221 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 42s 215ms/step - loss: 1.3495 - mae: 1.3495 - val_loss: 0.6358 - val_mae: 0.6358 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 41s 212ms/step - loss: 1.0158 - mae: 1.0158 - val_loss: 1.1569 - val_mae: 1.1569 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 41s 211ms/step - loss: 0.8192 - mae: 0.8192 - val_loss: 0.8760 - val_mae: 0.8760 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "196/196 [==============================] - 41s 211ms/step - loss: 0.7344 - mae: 0.7344 - val_loss: 0.7751 - val_mae: 0.7751 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "196/196 [==============================] - 42s 215ms/step - loss: 0.6652 - mae: 0.6652 - val_loss: 0.5248 - val_mae: 0.5248 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "196/196 [==============================] - 41s 212ms/step - loss: 0.6538 - mae: 0.6538 - val_loss: 0.7606 - val_mae: 0.7606 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "196/196 [==============================] - 42s 212ms/step - loss: 0.7604 - mae: 0.7604 - val_loss: 0.5694 - val_mae: 0.5694 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "196/196 [==============================] - 42s 216ms/step - loss: 0.5858 - mae: 0.5858 - val_loss: 0.3609 - val_mae: 0.3609 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "196/196 [==============================] - 42s 215ms/step - loss: 0.5348 - mae: 0.5348 - val_loss: 0.3097 - val_mae: 0.3097 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "196/196 [==============================] - 41s 212ms/step - loss: 0.5036 - mae: 0.5036 - val_loss: 0.3854 - val_mae: 0.3854 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "196/196 [==============================] - 42s 212ms/step - loss: 0.6714 - mae: 0.6714 - val_loss: 0.6887 - val_mae: 0.6887 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "196/196 [==============================] - 42s 216ms/step - loss: 0.5127 - mae: 0.5127 - val_loss: 0.2408 - val_mae: 0.2408 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "196/196 [==============================] - 42s 213ms/step - loss: 0.4856 - mae: 0.4856 - val_loss: 0.2545 - val_mae: 0.2545 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "196/196 [==============================] - 42s 214ms/step - loss: 0.5768 - mae: 0.5768 - val_loss: 0.5556 - val_mae: 0.5556 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "196/196 [==============================] - 42s 215ms/step - loss: 0.5410 - mae: 0.5410 - val_loss: 0.4828 - val_mae: 0.4828 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "196/196 [==============================] - 42s 216ms/step - loss: 0.5538 - mae: 0.5538 - val_loss: 0.5221 - val_mae: 0.5221 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "196/196 [==============================] - 43s 221ms/step - loss: 0.4919 - mae: 0.4919 - val_loss: 0.2207 - val_mae: 0.2207 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "196/196 [==============================] - 43s 218ms/step - loss: 0.4563 - mae: 0.4563 - val_loss: 0.2759 - val_mae: 0.2759 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "196/196 [==============================] - 43s 218ms/step - loss: 0.4678 - mae: 0.4678 - val_loss: 0.2660 - val_mae: 0.2660 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "196/196 [==============================] - 43s 218ms/step - loss: 0.4399 - mae: 0.4399 - val_loss: 0.2731 - val_mae: 0.2731 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "196/196 [==============================] - 43s 218ms/step - loss: 0.4225 - mae: 0.4225 - val_loss: 0.3658 - val_mae: 0.3658 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "196/196 [==============================] - ETA: 0s - loss: 0.4505 - mae: 0.4505\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "196/196 [==============================] - 43s 217ms/step - loss: 0.4505 - mae: 0.4505 - val_loss: 0.2452 - val_mae: 0.2452 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "196/196 [==============================] - 42s 216ms/step - loss: 0.4146 - mae: 0.4146 - val_loss: 0.3802 - val_mae: 0.3802 - lr: 9.0000e-04\n",
      "Epoch 25/100\n",
      "196/196 [==============================] - 43s 220ms/step - loss: 0.4092 - mae: 0.4092 - val_loss: 0.2092 - val_mae: 0.2092 - lr: 9.0000e-04\n",
      "Epoch 26/100\n",
      "196/196 [==============================] - 42s 216ms/step - loss: 0.4283 - mae: 0.4283 - val_loss: 0.2522 - val_mae: 0.2522 - lr: 9.0000e-04\n",
      "Epoch 27/100\n",
      "196/196 [==============================] - 43s 221ms/step - loss: 0.4134 - mae: 0.4134 - val_loss: 0.1933 - val_mae: 0.1933 - lr: 9.0000e-04\n",
      "Epoch 28/100\n",
      "196/196 [==============================] - 43s 218ms/step - loss: 0.4164 - mae: 0.4164 - val_loss: 0.2098 - val_mae: 0.2098 - lr: 9.0000e-04\n",
      "Epoch 29/100\n",
      "196/196 [==============================] - 43s 218ms/step - loss: 0.4951 - mae: 0.4951 - val_loss: 0.7883 - val_mae: 0.7883 - lr: 9.0000e-04\n",
      "Epoch 30/100\n",
      "196/196 [==============================] - 43s 219ms/step - loss: 0.5505 - mae: 0.5505 - val_loss: 0.3504 - val_mae: 0.3504 - lr: 9.0000e-04\n",
      "Epoch 31/100\n",
      "196/196 [==============================] - 43s 221ms/step - loss: 0.4465 - mae: 0.4465 - val_loss: 0.1924 - val_mae: 0.1924 - lr: 9.0000e-04\n",
      "Epoch 32/100\n",
      "196/196 [==============================] - 42s 216ms/step - loss: 0.3893 - mae: 0.3893 - val_loss: 0.5561 - val_mae: 0.5561 - lr: 9.0000e-04\n",
      "Epoch 33/100\n",
      "196/196 [==============================] - 42s 216ms/step - loss: 0.4166 - mae: 0.4166 - val_loss: 0.2552 - val_mae: 0.2552 - lr: 9.0000e-04\n",
      "Epoch 34/100\n",
      "196/196 [==============================] - 42s 216ms/step - loss: 0.5098 - mae: 0.5098 - val_loss: 0.5119 - val_mae: 0.5119 - lr: 9.0000e-04\n",
      "Epoch 35/100\n",
      "196/196 [==============================] - 42s 216ms/step - loss: 0.4167 - mae: 0.4167 - val_loss: 0.5393 - val_mae: 0.5393 - lr: 9.0000e-04\n",
      "Epoch 36/100\n",
      "196/196 [==============================] - ETA: 0s - loss: 0.4198 - mae: 0.4198\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "196/196 [==============================] - 43s 217ms/step - loss: 0.4198 - mae: 0.4198 - val_loss: 0.4132 - val_mae: 0.4132 - lr: 9.0000e-04\n",
      "Epoch 37/100\n",
      "196/196 [==============================] - 44s 223ms/step - loss: 0.4172 - mae: 0.4172 - val_loss: 0.1882 - val_mae: 0.1882 - lr: 8.1000e-04\n",
      "Epoch 38/100\n",
      "196/196 [==============================] - 43s 218ms/step - loss: 0.3923 - mae: 0.3923 - val_loss: 0.3749 - val_mae: 0.3749 - lr: 8.1000e-04\n",
      "Epoch 39/100\n",
      "196/196 [==============================] - 42s 217ms/step - loss: 0.3963 - mae: 0.3963 - val_loss: 0.2901 - val_mae: 0.2901 - lr: 8.1000e-04\n",
      "Epoch 40/100\n",
      "196/196 [==============================] - 42s 216ms/step - loss: 0.3711 - mae: 0.3711 - val_loss: 0.3662 - val_mae: 0.3662 - lr: 8.1000e-04\n",
      "Epoch 41/100\n",
      "196/196 [==============================] - 43s 219ms/step - loss: 0.3760 - mae: 0.3760 - val_loss: 0.1865 - val_mae: 0.1865 - lr: 8.1000e-04\n",
      "Epoch 42/100\n",
      "196/196 [==============================] - 42s 215ms/step - loss: 0.3584 - mae: 0.3584 - val_loss: 0.2082 - val_mae: 0.2082 - lr: 8.1000e-04\n",
      "Epoch 43/100\n",
      "196/196 [==============================] - 42s 217ms/step - loss: 0.3665 - mae: 0.3665 - val_loss: 0.4204 - val_mae: 0.4204 - lr: 8.1000e-04\n",
      "Epoch 44/100\n",
      "196/196 [==============================] - 43s 222ms/step - loss: 0.3600 - mae: 0.3600 - val_loss: 0.1517 - val_mae: 0.1517 - lr: 8.1000e-04\n",
      "Epoch 45/100\n",
      "196/196 [==============================] - 43s 217ms/step - loss: 0.3725 - mae: 0.3725 - val_loss: 0.6490 - val_mae: 0.6490 - lr: 8.1000e-04\n",
      "Epoch 46/100\n",
      "196/196 [==============================] - 42s 216ms/step - loss: 0.3578 - mae: 0.3578 - val_loss: 0.3246 - val_mae: 0.3246 - lr: 8.1000e-04\n",
      "Epoch 47/100\n",
      "196/196 [==============================] - 42s 215ms/step - loss: 0.3579 - mae: 0.3579 - val_loss: 0.1907 - val_mae: 0.1907 - lr: 8.1000e-04\n",
      "Epoch 48/100\n",
      "196/196 [==============================] - 42s 215ms/step - loss: 0.3702 - mae: 0.3702 - val_loss: 0.1629 - val_mae: 0.1629 - lr: 8.1000e-04\n",
      "Epoch 49/100\n",
      "196/196 [==============================] - ETA: 0s - loss: 0.3773 - mae: 0.3773\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "196/196 [==============================] - 42s 215ms/step - loss: 0.3773 - mae: 0.3773 - val_loss: 0.1825 - val_mae: 0.1825 - lr: 8.1000e-04\n",
      "Epoch 50/100\n",
      "196/196 [==============================] - 42s 216ms/step - loss: 0.4093 - mae: 0.4093 - val_loss: 0.5873 - val_mae: 0.5873 - lr: 7.2900e-04\n",
      "Epoch 51/100\n",
      "196/196 [==============================] - 42s 217ms/step - loss: 0.3956 - mae: 0.3956 - val_loss: 0.2449 - val_mae: 0.2449 - lr: 7.2900e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "196/196 [==============================] - 43s 217ms/step - loss: 0.3769 - mae: 0.3769 - val_loss: 0.1842 - val_mae: 0.1842 - lr: 7.2900e-04\n",
      "Epoch 53/100\n",
      "196/196 [==============================] - 42s 216ms/step - loss: 0.3719 - mae: 0.3719 - val_loss: 0.1754 - val_mae: 0.1754 - lr: 7.2900e-04\n",
      "Epoch 54/100\n",
      "196/196 [==============================] - 43s 220ms/step - loss: 0.3553 - mae: 0.3553 - val_loss: 0.1414 - val_mae: 0.1414 - lr: 7.2900e-04\n",
      "Epoch 55/100\n",
      "196/196 [==============================] - 42s 215ms/step - loss: 0.3473 - mae: 0.3473 - val_loss: 0.1651 - val_mae: 0.1651 - lr: 7.2900e-04\n",
      "Epoch 56/100\n",
      "196/196 [==============================] - 42s 215ms/step - loss: 0.3812 - mae: 0.3812 - val_loss: 0.2357 - val_mae: 0.2357 - lr: 7.2900e-04\n",
      "Epoch 57/100\n",
      "196/196 [==============================] - 42s 216ms/step - loss: 0.3687 - mae: 0.3687 - val_loss: 0.1559 - val_mae: 0.1559 - lr: 7.2900e-04\n",
      "Epoch 58/100\n",
      "196/196 [==============================] - 42s 216ms/step - loss: 0.3925 - mae: 0.3925 - val_loss: 0.1987 - val_mae: 0.1987 - lr: 7.2900e-04\n",
      "Epoch 59/100\n",
      "196/196 [==============================] - ETA: 0s - loss: 0.3705 - mae: 0.3705\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
      "196/196 [==============================] - 43s 217ms/step - loss: 0.3705 - mae: 0.3705 - val_loss: 0.6187 - val_mae: 0.6187 - lr: 7.2900e-04\n",
      "Epoch 60/100\n",
      "196/196 [==============================] - 42s 216ms/step - loss: 0.3471 - mae: 0.3471 - val_loss: 0.2239 - val_mae: 0.2239 - lr: 6.5610e-04\n",
      "Epoch 61/100\n",
      "196/196 [==============================] - 43s 220ms/step - loss: 0.3388 - mae: 0.3388 - val_loss: 0.1262 - val_mae: 0.1262 - lr: 6.5610e-04\n",
      "Epoch 62/100\n",
      "196/196 [==============================] - 42s 215ms/step - loss: 0.3391 - mae: 0.3391 - val_loss: 0.1431 - val_mae: 0.1431 - lr: 6.5610e-04\n",
      "Epoch 63/100\n",
      "196/196 [==============================] - 42s 215ms/step - loss: 0.3435 - mae: 0.3435 - val_loss: 0.2795 - val_mae: 0.2795 - lr: 6.5610e-04\n",
      "Epoch 64/100\n",
      "196/196 [==============================] - 43s 219ms/step - loss: 0.3225 - mae: 0.3225 - val_loss: 0.1088 - val_mae: 0.1088 - lr: 6.5610e-04\n",
      "Epoch 65/100\n",
      "196/196 [==============================] - 42s 216ms/step - loss: 0.3194 - mae: 0.3194 - val_loss: 0.2604 - val_mae: 0.2604 - lr: 6.5610e-04\n",
      "Epoch 66/100\n",
      "196/196 [==============================] - 42s 217ms/step - loss: 0.3300 - mae: 0.3300 - val_loss: 0.1460 - val_mae: 0.1460 - lr: 6.5610e-04\n",
      "Epoch 67/100\n",
      "196/196 [==============================] - 43s 217ms/step - loss: 0.3251 - mae: 0.3251 - val_loss: 0.2470 - val_mae: 0.2470 - lr: 6.5610e-04\n",
      "Epoch 68/100\n",
      "196/196 [==============================] - 42s 216ms/step - loss: 0.3274 - mae: 0.3274 - val_loss: 0.1643 - val_mae: 0.1643 - lr: 6.5610e-04\n",
      "Epoch 69/100\n",
      "196/196 [==============================] - ETA: 0s - loss: 0.3259 - mae: 0.3259\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
      "196/196 [==============================] - 42s 215ms/step - loss: 0.3259 - mae: 0.3259 - val_loss: 0.2335 - val_mae: 0.2335 - lr: 6.5610e-04\n",
      "Epoch 70/100\n",
      "196/196 [==============================] - 42s 215ms/step - loss: 0.3369 - mae: 0.3369 - val_loss: 0.1350 - val_mae: 0.1350 - lr: 5.9049e-04\n",
      "Epoch 71/100\n",
      "196/196 [==============================] - 43s 219ms/step - loss: 0.3207 - mae: 0.3207 - val_loss: 0.1066 - val_mae: 0.1066 - lr: 5.9049e-04\n",
      "Epoch 72/100\n",
      "196/196 [==============================] - 42s 216ms/step - loss: 0.3370 - mae: 0.3370 - val_loss: 0.1236 - val_mae: 0.1236 - lr: 5.9049e-04\n",
      "Epoch 73/100\n",
      "196/196 [==============================] - 43s 220ms/step - loss: 0.3181 - mae: 0.3181 - val_loss: 0.0995 - val_mae: 0.0995 - lr: 5.9049e-04\n",
      "Epoch 74/100\n",
      "196/196 [==============================] - 42s 216ms/step - loss: 0.3306 - mae: 0.3306 - val_loss: 0.3811 - val_mae: 0.3811 - lr: 5.9049e-04\n",
      "Epoch 75/100\n",
      "196/196 [==============================] - 42s 216ms/step - loss: 0.3397 - mae: 0.3397 - val_loss: 0.1329 - val_mae: 0.1329 - lr: 5.9049e-04\n",
      "Epoch 76/100\n",
      "196/196 [==============================] - 42s 215ms/step - loss: 0.3630 - mae: 0.3630 - val_loss: 0.2293 - val_mae: 0.2293 - lr: 5.9049e-04\n",
      "Epoch 77/100\n",
      "196/196 [==============================] - 42s 215ms/step - loss: 0.3666 - mae: 0.3666 - val_loss: 0.2749 - val_mae: 0.2749 - lr: 5.9049e-04\n",
      "Epoch 78/100\n",
      "196/196 [==============================] - ETA: 0s - loss: 0.3259 - mae: 0.3259\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
      "196/196 [==============================] - 42s 215ms/step - loss: 0.3259 - mae: 0.3259 - val_loss: 0.1539 - val_mae: 0.1539 - lr: 5.9049e-04\n",
      "Epoch 79/100\n",
      "196/196 [==============================] - 42s 215ms/step - loss: 0.3178 - mae: 0.3178 - val_loss: 0.1889 - val_mae: 0.1889 - lr: 5.3144e-04\n",
      "Epoch 80/100\n",
      "196/196 [==============================] - 42s 215ms/step - loss: 0.3205 - mae: 0.3205 - val_loss: 0.1220 - val_mae: 0.1220 - lr: 5.3144e-04\n",
      "Epoch 81/100\n",
      "196/196 [==============================] - 42s 216ms/step - loss: 0.3072 - mae: 0.3072 - val_loss: 0.1222 - val_mae: 0.1222 - lr: 5.3144e-04\n",
      "Epoch 82/100\n",
      "196/196 [==============================] - 43s 217ms/step - loss: 0.3268 - mae: 0.3268 - val_loss: 0.1787 - val_mae: 0.1787 - lr: 5.3144e-04\n",
      "Epoch 83/100\n",
      "196/196 [==============================] - ETA: 0s - loss: 0.3150 - mae: 0.3150\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
      "196/196 [==============================] - 42s 217ms/step - loss: 0.3150 - mae: 0.3150 - val_loss: 0.1147 - val_mae: 0.1147 - lr: 5.3144e-04\n",
      "Epoch 84/100\n",
      "196/196 [==============================] - 42s 216ms/step - loss: 0.3080 - mae: 0.3080 - val_loss: 0.2645 - val_mae: 0.2645 - lr: 4.7830e-04\n",
      "Epoch 85/100\n",
      "196/196 [==============================] - 43s 220ms/step - loss: 0.3015 - mae: 0.3015 - val_loss: 0.0984 - val_mae: 0.0984 - lr: 4.7830e-04\n",
      "Epoch 86/100\n",
      "196/196 [==============================] - 42s 216ms/step - loss: 0.3172 - mae: 0.3172 - val_loss: 0.1903 - val_mae: 0.1903 - lr: 4.7830e-04\n",
      "Epoch 87/100\n",
      "196/196 [==============================] - 43s 217ms/step - loss: 0.3002 - mae: 0.3002 - val_loss: 0.2102 - val_mae: 0.2102 - lr: 4.7830e-04\n",
      "Epoch 88/100\n",
      "196/196 [==============================] - 43s 217ms/step - loss: 0.3276 - mae: 0.3276 - val_loss: 0.2171 - val_mae: 0.2171 - lr: 4.7830e-04\n",
      "Epoch 89/100\n",
      "196/196 [==============================] - 42s 216ms/step - loss: 0.3125 - mae: 0.3125 - val_loss: 0.1193 - val_mae: 0.1193 - lr: 4.7830e-04\n",
      "Epoch 90/100\n",
      "196/196 [==============================] - ETA: 0s - loss: 0.3047 - mae: 0.3047\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n",
      "196/196 [==============================] - 42s 216ms/step - loss: 0.3047 - mae: 0.3047 - val_loss: 0.1447 - val_mae: 0.1447 - lr: 4.7830e-04\n",
      "Epoch 91/100\n",
      "196/196 [==============================] - 42s 215ms/step - loss: 0.2934 - mae: 0.2934 - val_loss: 0.1108 - val_mae: 0.1108 - lr: 4.3047e-04\n",
      "Epoch 92/100\n",
      "196/196 [==============================] - 43s 219ms/step - loss: 0.3013 - mae: 0.3013 - val_loss: 0.0898 - val_mae: 0.0898 - lr: 4.3047e-04\n",
      "Epoch 93/100\n",
      "196/196 [==============================] - 42s 216ms/step - loss: 0.2930 - mae: 0.2930 - val_loss: 0.1756 - val_mae: 0.1756 - lr: 4.3047e-04\n",
      "Epoch 94/100\n",
      "196/196 [==============================] - 42s 217ms/step - loss: 0.3000 - mae: 0.3000 - val_loss: 0.1532 - val_mae: 0.1532 - lr: 4.3047e-04\n",
      "Epoch 95/100\n",
      "196/196 [==============================] - 43s 217ms/step - loss: 0.2932 - mae: 0.2932 - val_loss: 0.1459 - val_mae: 0.1459 - lr: 4.3047e-04\n",
      "Epoch 96/100\n",
      "196/196 [==============================] - 42s 216ms/step - loss: 0.2940 - mae: 0.2940 - val_loss: 0.1002 - val_mae: 0.1002 - lr: 4.3047e-04\n",
      "Epoch 97/100\n",
      "196/196 [==============================] - ETA: 0s - loss: 0.2929 - mae: 0.2929\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.00038742052274756136.\n",
      "196/196 [==============================] - 42s 216ms/step - loss: 0.2929 - mae: 0.2929 - val_loss: 0.1341 - val_mae: 0.1341 - lr: 4.3047e-04\n",
      "Epoch 98/100\n",
      "196/196 [==============================] - 42s 215ms/step - loss: 0.2914 - mae: 0.2914 - val_loss: 0.0918 - val_mae: 0.0918 - lr: 3.8742e-04\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 42s 215ms/step - loss: 0.2870 - mae: 0.2870 - val_loss: 0.1227 - val_mae: 0.1227 - lr: 3.8742e-04\n",
      "Epoch 100/100\n",
      "196/196 [==============================] - 42s 215ms/step - loss: 0.2885 - mae: 0.2885 - val_loss: 0.1153 - val_mae: 0.1153 - lr: 3.8742e-04\n"
     ]
    }
   ],
   "source": [
    "# Start training model\n",
    "Epochs=100\n",
    "Batch_Size=32\n",
    "# Select batch size according to your Graphic card \n",
    "#\n",
    "#X_train,X_test,Y_train,Y_test\n",
    "history=model.fit(\n",
    "\t\t\t\tX_train,\n",
    "\t\t\t\tY_train,\n",
    "\t\t\t\tvalidation_data=(X_test,Y_test),\n",
    "\t\t\t\tbatch_size=Batch_Size,\n",
    "\t\t\t\tepochs=Epochs,\n",
    "\t\t\t\tcallbacks=[model_checkpoint,reduce_lr]\n",
    "\t\t\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acfc7e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mae', 'val_loss', 'val_mae', 'lr'])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'val_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# summarize history for accuracy\u001b[39;00m\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_accuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_accuracy'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['mae'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0bf0059",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 81). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\safwa\\AppData\\Local\\Temp\\tmpbxzbwuwa\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\safwa\\AppData\\Local\\Temp\\tmpbxzbwuwa\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 4s 53ms/step\n",
      "[[10.013145  ]\n",
      " [13.959213  ]\n",
      " [21.05962   ]\n",
      " [11.012989  ]\n",
      " [13.883623  ]\n",
      " [ 9.0488205 ]\n",
      " [ 4.888017  ]\n",
      " [ 0.94989884]\n",
      " [ 8.97307   ]\n",
      " [19.87367   ]]\n",
      "[10. 14. 21. 11. 14.  9.  5.  1.  9. 20.]\n"
     ]
    }
   ],
   "source": [
    "# Before training you can delete image_array and label_array to increase ram memory \n",
    "\n",
    "# Some error correction\n",
    "# This code will be in the description so you can cross check everything\n",
    "# Save and run \n",
    "# Everything is working\n",
    "\n",
    "# after the training is done load best model\n",
    "\n",
    "model.load_weights(ckp_path)\n",
    "\n",
    "# convert model to tensorflow lite model\n",
    "\n",
    "converter=tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model=converter.convert()\n",
    "\n",
    "# save model\n",
    "with open(\"model2224.tflite\",\"wb\") as f:\n",
    "\tf.write(tflite_model)\n",
    "\n",
    "# if you want to see prediction result on test dataset\n",
    "prediction_val=model.predict(X_test,batch_size=32)\n",
    "\n",
    "# print first 10 values\n",
    "print(prediction_val[:10])\n",
    "# print first 10 values of Y_test\n",
    "print(Y_test[:10])\n",
    "\n",
    "# Save and run this python file\n",
    "# Before that I will show you\n",
    "# loss: 0.4074 - mae: 0.4074 - val_loss: 0.3797 - val_mae: 0.3797\n",
    "# we have mae and val_mae:\n",
    "# mae: Is on X_train\n",
    "# val_mae: X_test\n",
    "# If val_mae is reducing that means your model is improving.\n",
    "\n",
    "# I will show you the result after the training is over\n",
    "\n",
    "#40/40 [==============================] - 8s 202ms/step - loss: 0.0552 - mae: 0.0552 - val_loss: 0.0380 - val_mae: 0.0380 - lr: 2.5419e-04 (224 Input 5 Classes)\n",
    "#196/196 [==============================] - 42s 215ms/step - loss: 0.2885 - mae: 0.2885 - val_loss: 0.1153 - val_mae: 0.1153 - lr: 3.8742e-04"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
