{"cells":[{"cell_type":"code","execution_count":1,"id":"b6989750","metadata":{"id":"b6989750","executionInfo":{"status":"ok","timestamp":1670866123026,"user_tz":-300,"elapsed":5588,"user":{"displayName":"M ABDULLAH (Comedian)","userId":"08195445713187952273"}}},"outputs":[],"source":["import numpy as np\n","import keras.utils as image\n","import cv2\n","import os\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from keras.preprocessing.image import ImageDataGenerator\n","import sys\n","from matplotlib import pyplot\n","from keras.models import Sequential\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.layers import Dropout\n","import warnings\n","warnings.filterwarnings('ignore')\n","import pickle"]},{"cell_type":"code","execution_count":2,"id":"2e6f477d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2e6f477d","executionInfo":{"status":"ok","timestamp":1670866513798,"user_tz":-300,"elapsed":473,"user":{"displayName":"M ABDULLAH (Comedian)","userId":"08195445713187952273"}},"outputId":"4931ba37-a6bf-4fc1-9c42-75207c12b46f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 0 images belonging to 6 classes.\n"]}],"source":["train_datagen = ImageDataGenerator(rescale = 1./255,\n","                                   shear_range = 0.2,\n","                                   zoom_range = 0.2,\n","                                   horizontal_flip = True)\n","training_set = train_datagen.flow_from_directory(r\"C:\\Users\\Abdullah\\Desktop\\Latest_FYP_APP\\dataset\\train\",\n","                                                 target_size = (128, 128),\n","                                                 batch_size = 32,\n","                                                 class_mode = 'binary',classes=[\"freshapples\",\"freshbanana\",\"FreshGrape\",\"rottenapples\",\"rottenbanana\",\"RottenGrape\"])\n","# print(len(training_set.classes))"]},{"cell_type":"code","execution_count":null,"id":"71d8138e","metadata":{"id":"71d8138e","outputId":"20295cf8-54b8-4a14-ebbc-0eb7367c0f4d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 2307 images belonging to 6 classes.\n","Image Processing.......Completed\n"]}],"source":["test_datagen = ImageDataGenerator(rescale = 1./255)\n","test_set = test_datagen.flow_from_directory(r\"C:\\Users\\Abdullah\\Desktop\\Latest_FYP_APP\\dataset\\test\",\n","                                            target_size = (128, 128),\n","                                            batch_size = 32,\n","                                            class_mode = 'binary',classes=[\"freshapples\",\"freshbanana\",\"FreshGrape\",\"rottenapples\",\"rottenbanana\",\"RottenGrape\"])\n","print(\"Image Processing.......Completed\")"]},{"cell_type":"code","execution_count":null,"id":"a7a97960","metadata":{"id":"a7a97960"},"outputs":[],"source":["cnn = tf.keras.models.Sequential()\n","cnn.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(128,128, 3)))\n","cnn.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n","cnn.add(MaxPooling2D((2, 2)))\n","cnn.add(Dropout(0.2))\n","cnn.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n","cnn.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n","cnn.add(MaxPooling2D((2, 2)))\n","cnn.add(Dropout(0.2))\n","cnn.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n","cnn.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n","cnn.add(MaxPooling2D((2, 2)))\n","cnn.add(Dropout(0.2))\n","cnn.add(Flatten())\n","cnn.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n","cnn.add(Dropout(0.2))\n","cnn.add(Dense(6, activation='softmax'))\n","cnn.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"id":"96786e85","metadata":{"id":"96786e85","outputId":"6e3df2c4-52ce-4b70-ba24-86b7832f5211"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 128, 128, 32)      896       \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 128, 128, 32)      9248      \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 64, 64, 32)       0         \n"," )                                                               \n","                                                                 \n"," dropout (Dropout)           (None, 64, 64, 32)        0         \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 64, 64, 64)        18496     \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 64, 64, 64)        36928     \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 32, 32, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_1 (Dropout)         (None, 32, 32, 64)        0         \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 32, 32, 128)       73856     \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 32, 32, 128)       147584    \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 16, 16, 128)      0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_2 (Dropout)         (None, 16, 16, 128)       0         \n","                                                                 \n"," flatten (Flatten)           (None, 32768)             0         \n","                                                                 \n"," dense (Dense)               (None, 128)               4194432   \n","                                                                 \n"," dropout_3 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 6)                 774       \n","                                                                 \n","=================================================================\n","Total params: 4,482,214\n","Trainable params: 4,482,214\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["cnn.summary()"]},{"cell_type":"code","execution_count":null,"id":"5fc925f3","metadata":{"id":"5fc925f3","outputId":"c19d6ea7-7ab1-44fc-fa8b-97e490f4f3fd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","294/294 [==============================] - 1209s 4s/step - loss: 1.1972 - accuracy: 0.6229 - val_loss: 0.5154 - val_accuracy: 0.7876\n","Epoch 2/5\n","294/294 [==============================] - 1071s 4s/step - loss: 0.3283 - accuracy: 0.8782 - val_loss: 0.2370 - val_accuracy: 0.9120\n","Epoch 3/5\n","294/294 [==============================] - 1117s 4s/step - loss: 0.2449 - accuracy: 0.9111 - val_loss: 0.1840 - val_accuracy: 0.9354\n","Epoch 4/5\n","293/294 [============================>.] - ETA: 5s - loss: 0.2326 - accuracy: 0.9137 "]}],"source":["cnn.fit(x = training_set, validation_data = test_set, epochs = 5)"]},{"cell_type":"code","execution_count":null,"id":"b135675f","metadata":{"scrolled":false,"id":"b135675f"},"outputs":[],"source":["img = image.load_img(r\"C:\\Users\\Abdullah\\Desktop\\Latest_FYP_APP\\dataset\\test\\freshgrape\\FreshGrape (135).jpg\"\n","                     ,target_size = (128,128))\n","plt.imshow(img)\n","test_image=img\n","test_image = image.img_to_array(test_image)\n","test_image = np.expand_dims(test_image, axis = 0)\n","result = cnn.predict(test_image)\n","training_set.class_indices\n","# print(len(result[0]))\n","# print(max(result[0]))\n","print(result[0])\n","if result[0][0] ==1:\n","    print(\"Apple\")\n","    print(\"Apple is Fresh\")\n","if result[0][1] == 1:\n","    print(\"Banana\")\n","    print(\"Banana is Fresh\")\n","if result[0][2] == 1:\n","    print(\"Grape\")\n","    print(\"Grape is Fresh\")\n","if result[0][3] == 1:\n","    print(\"Apple\")\n","    print(\"Apple is Rotten\")\n","if result[0][4] == 1:\n","    print(\"Banana\")\n","    print(\"Banana is Rotten\")\n","if result[0][5] == 1:\n","    print(\"Grape\")\n","    print(\"Grape is Rotten\")"]},{"cell_type":"code","execution_count":null,"id":"36e33e95","metadata":{"id":"36e33e95"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}